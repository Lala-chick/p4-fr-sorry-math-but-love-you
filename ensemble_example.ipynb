{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4fb40de-413b-4ab0-a59e-e8c4c13f4938",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-da240921f6fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from metrics import word_error_rate, sentence_acc\n",
    "from checkpoint import load_checkpoint\n",
    "from dataset import LoadEvalDataset, collate_eval_batch, START, PAD\n",
    "from flags import Flags\n",
    "from utils import id_to_string, get_network, get_optimizer\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be41016-ed81-4c16-afbd-341aec392592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.20.3\n",
      "Uninstalling numpy-1.20.3:\n",
      "  Successfully uninstalled numpy-1.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b316b-2ff4-4d70-99ab-d4ee40013765",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "parser = easydict.EasyDict({\n",
    " \n",
    "        \"checkpoint\": [\"/opt/ml/p4-fr-sorry-math-but-love-you/log/attention_50/0048.pth\",\n",
    "                      \"/opt/ml/p4-fr-sorry-math-but-love-you/log/attention_50/0043.pth\"],\n",
    "    \n",
    "})\n",
    "max_sequence = 230\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650239b3-90b4-4962-bcc5-909bece1d9b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3bc7bc381b1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(21) #\n",
    "random.seed(21) #\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "612fa68f-f90d-47c3-b842-61816c3b0364",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'is_cuda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-08ff140c6007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhardware\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhardware\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'is_cuda' is not defined"
     ]
    }
   ],
   "source": [
    "hardware = \"cuda\" if is_cuda else \"cpu\"\n",
    "device = torch.device(hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecfa0921-f69c-43ca-b579-9ccb326e8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_gt = \"\\sin \" * max_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab0a14d-5cdf-4837-bbd5-143ee0d52f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed = A.Compose(\n",
    "#         [\n",
    "#             A.Resize(128, 128), #\n",
    "#             ToTensorV2(),\n",
    "#         ]\n",
    "#     )\n",
    "transformed = transforms.Compose(\n",
    "        [\n",
    "            # Resize so all images have the same size\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c7354e6-9738-4d7b-ab69-d13cca6613ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "models = []\n",
    "token_to_id_ = load_checkpoint(parser.checkpoint[0], cuda=is_cuda)[\"token_to_id\"]\n",
    "id_to_token_ = load_checkpoint(parser.checkpoint[0], cuda=is_cuda)[\"id_to_token\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45ff2a59-cb0c-4373-be8e-032666e576f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dir = os.environ.get('SM_CHANNEL_EVAL', '/opt/ml/input/data/')\n",
    "file_path = os.path.join(eval_dir, 'eval_dataset/input.txt')\n",
    "root = os.path.join(os.path.dirname(file_path), 'images')\n",
    "output_dir = os.environ.get('SM_OUTPUT_DATA_DIR', 'submit')\n",
    "with open(file_path, \"r\") as fd:\n",
    "    reader = csv.reader(fd, delimiter=\"\\t\")\n",
    "    data = list(reader)\n",
    "test_data = [[os.path.join(root, x[0]), x[0], dummy_gt] for x in data]\n",
    "test_dataset = LoadEvalDataset(\n",
    "    test_data, token_to_id_, id_to_token_, crop=False, transform=transformed,\n",
    "    rgb=1 #\n",
    ")\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4, #\n",
    "    collate_fn=collate_eval_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49537d24-b78c-4426-bda6-44a5eb8b5a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parser_checkpoint in parser.checkpoint:\n",
    "    checkpoint = load_checkpoint(parser_checkpoint, cuda=is_cuda)\n",
    "    options = Flags(checkpoint[\"configs\"]).get()\n",
    "    model_checkpoint = checkpoint[\"model\"]\n",
    "    model = get_network(options.network, options, model_checkpoint, device, test_dataset)\n",
    "    model.eval()\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9132fcea-0049-4773-b1e0-8a24709fed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.68s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for d in tqdm(test_data_loader):\n",
    "    input = d[\"image\"].to(device)\n",
    "    expected = d[\"truth\"][\"encoded\"].to(device)\n",
    "    decoded_values = None\n",
    "    for model in models:\n",
    "        output = model(input, expected, False, 0.0)\n",
    "        if decoded_values is None:\n",
    "            decoded_values = output.transpose(1, 2)\n",
    "        else:\n",
    "            decoded_values += output.transpose(1, 2)\n",
    "    decoded_values /= len(models)\n",
    "    _, sequence = torch.topk(decoded_values, 1, dim=1)\n",
    "    sequence = sequence.squeeze(1)\n",
    "    sequence_str = id_to_string(sequence, test_data_loader, do_eval=1)\n",
    "#     print(sequence_str)\n",
    "    for path, predicted in zip(d[\"file_path\"], sequence_str):\n",
    "        results.append((path, predicted))\n",
    "        \n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(os.path.join(output_dir, \"output.csv\"), \"w\") as w:\n",
    "    for path, predicted in results:\n",
    "        w.write(path + \"\\t\" + predicted + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe3cad0-e9ce-407d-a988-0816a81f099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay          99G   30G   64G  32% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs            45G     0   45G   0% /sys/fs/cgroup\n",
      "shm             1.0G  156K  1.0G   1% /dev/shm\n",
      "/dev/xvdb1       99G   30G   64G  32% /etc/hosts\n",
      "tmpfs            45G   12K   45G   1% /proc/driver/nvidia\n",
      "/dev/xvda1       48G   32G   14G  71% /usr/bin/nvidia-smi\n",
      "tmpfs           8.9G   17M  8.9G   1% /run/nvidia-persistenced/socket\n",
      "udev             45G     0   45G   0% /dev/nvidia0\n",
      "tmpfs            45G     0   45G   0% /proc/acpi\n",
      "tmpfs            45G     0   45G   0% /proc/scsi\n",
      "tmpfs            45G     0   45G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f2b1da-e554-412c-8d62-afc598e45439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.4.9-py3-none-any.whl (346 kB)\n",
      "\u001b[K     |████████████████████████████████| 346 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.8.2+cu101)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.7.1+cu101)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (8.1.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (3.10.0.0)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.4.9\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d48fd1b7-dfae-43f0-9878-68fb59236df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay          99G   39G   55G  42% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs            45G     0   45G   0% /sys/fs/cgroup\n",
      "shm             1.0G  103M  922M  10% /dev/shm\n",
      "/dev/xvdb1       99G   39G   55G  42% /etc/hosts\n",
      "tmpfs            45G   12K   45G   1% /proc/driver/nvidia\n",
      "/dev/xvda1       48G   32G   14G  71% /usr/bin/nvidia-smi\n",
      "tmpfs           8.9G   17M  8.9G   1% /run/nvidia-persistenced/socket\n",
      "udev             45G     0   45G   0% /dev/nvidia0\n",
      "tmpfs            45G     0   45G   0% /proc/acpi\n",
      "tmpfs            45G     0   45G   0% /proc/scsi\n",
      "tmpfs            45G     0   45G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0348c43-11f8-442d-aeef-208197311a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
